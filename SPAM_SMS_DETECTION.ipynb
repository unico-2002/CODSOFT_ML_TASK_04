{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Data Preparation"
      ],
      "metadata": {
        "id": "RPDCo3dBa9Xn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6z3Vkbl6aSxZ",
        "outputId": "a8ed116d-b6fe-40de-9c3c-4505654f6f99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5572 entries, 0 to 5571\n",
            "Data columns (total 5 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   v1          5572 non-null   object\n",
            " 1   v2          5572 non-null   object\n",
            " 2   Unnamed: 2  50 non-null     object\n",
            " 3   Unnamed: 3  12 non-null     object\n",
            " 4   Unnamed: 4  6 non-null      object\n",
            "dtypes: object(5)\n",
            "memory usage: 217.8+ KB\n",
            "None\n",
            "     v1                                                 v2 Unnamed: 2  \\\n",
            "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
            "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
            "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
            "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
            "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
            "\n",
            "  Unnamed: 3 Unnamed: 4  \n",
            "0        NaN        NaN  \n",
            "1        NaN        NaN  \n",
            "2        NaN        NaN  \n",
            "3        NaN        NaN  \n",
            "4        NaN        NaN  \n",
            "label\n",
            "0    0.865937\n",
            "1    0.134063\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import joblib\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('spam.csv', encoding='latin-1')\n",
        "\n",
        "# Display basic information about the dataset\n",
        "print(df.info())\n",
        "print(df.head())\n",
        "\n",
        "# Drop unnecessary columns and rename columns for convenience\n",
        "df = df.drop(columns=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'])\n",
        "df.columns = ['label', 'message']\n",
        "\n",
        "# Map the labels to binary values\n",
        "df['label'] = df['label'].map({'ham': 0, 'spam': 1})\n",
        "\n",
        "# Check for class distribution\n",
        "print(df['label'].value_counts(normalize=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Extraction"
      ],
      "metadata": {
        "id": "RrG3DFAka1vT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['message'], df['label'], test_size=0.2, random_state=42, stratify=df['label'])\n",
        "\n",
        "# Use TF-IDF Vectorizer to convert text to numerical features\n",
        "tfidf = TfidfVectorizer(stop_words='english', max_features=5000)\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf.transform(X_test)"
      ],
      "metadata": {
        "id": "tDk8OT4ra1K2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Training\n"
      ],
      "metadata": {
        "id": "ngKuAVcxau-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Naive Bayes\n",
        "nb_model = MultinomialNB()\n",
        "nb_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Logistic Regression\n",
        "log_reg_model = LogisticRegression(max_iter=1000)\n",
        "log_reg_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Support Vector Machine\n",
        "svm_model = SVC(kernel='linear')\n",
        "svm_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Save the models and the vectorizer\n",
        "joblib.dump(nb_model, 'naive_bayes_model.pkl')\n",
        "joblib.dump(log_reg_model, 'logistic_regression_model.pkl')\n",
        "joblib.dump(svm_model, 'svm_model.pkl')\n",
        "joblib.dump(tfidf, 'tfidf_vectorizer.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUNQlFOMasYF",
        "outputId": "17133aff-4fa6-4f86-c83d-52edbe64b99f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tfidf_vectorizer.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Evaluation"
      ],
      "metadata": {
        "id": "cUByLcVsancu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Naive Bayes\n",
        "y_pred_nb = nb_model.predict(X_test_tfidf)\n",
        "print(\"Naive Bayes Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_nb)}\")\n",
        "print(confusion_matrix(y_test, y_pred_nb))\n",
        "print(classification_report(y_test, y_pred_nb))\n",
        "\n",
        "# Evaluate Logistic Regression\n",
        "y_pred_log_reg = log_reg_model.predict(X_test_tfidf)\n",
        "print(\"\\nLogistic Regression Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_log_reg)}\")\n",
        "print(confusion_matrix(y_test, y_pred_log_reg))\n",
        "print(classification_report(y_test, y_pred_log_reg))\n",
        "\n",
        "# Evaluate Support Vector Machine\n",
        "y_pred_svm = svm_model.predict(X_test_tfidf)\n",
        "print(\"\\nSupport Vector Machine Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_svm)}\")\n",
        "print(confusion_matrix(y_test, y_pred_svm))\n",
        "print(classification_report(y_test, y_pred_svm))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pr2HyYxhadzD",
        "outputId": "c986919a-c30d-4825-cd60-911a8dc0669d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Results:\n",
            "Accuracy: 0.9704035874439462\n",
            "[[965   1]\n",
            " [ 32 117]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98       966\n",
            "           1       0.99      0.79      0.88       149\n",
            "\n",
            "    accuracy                           0.97      1115\n",
            "   macro avg       0.98      0.89      0.93      1115\n",
            "weighted avg       0.97      0.97      0.97      1115\n",
            "\n",
            "\n",
            "Logistic Regression Results:\n",
            "Accuracy: 0.968609865470852\n",
            "[[965   1]\n",
            " [ 34 115]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98       966\n",
            "           1       0.99      0.77      0.87       149\n",
            "\n",
            "    accuracy                           0.97      1115\n",
            "   macro avg       0.98      0.89      0.93      1115\n",
            "weighted avg       0.97      0.97      0.97      1115\n",
            "\n",
            "\n",
            "Support Vector Machine Results:\n",
            "Accuracy: 0.9811659192825112\n",
            "[[964   2]\n",
            " [ 19 130]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       966\n",
            "           1       0.98      0.87      0.93       149\n",
            "\n",
            "    accuracy                           0.98      1115\n",
            "   macro avg       0.98      0.94      0.96      1115\n",
            "weighted avg       0.98      0.98      0.98      1115\n",
            "\n"
          ]
        }
      ]
    }
  ]
}